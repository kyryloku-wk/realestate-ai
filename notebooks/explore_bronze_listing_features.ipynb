{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict, Any, Mapping, Optional\n",
    "import numpy as np\n",
    "\n",
    "from realestateai.data.postgres.utils import query_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = query_to_dataframe(\"\"\"SELECT * FROM listings_bronze\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf46fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ecaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads = df[\"payload\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9af1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(payloads[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get_field(output_dict, field_name, data_dict):\n",
    "    output_dict[field_name] = data_dict.get(field_name, None)\n",
    "\n",
    "def extract_char_fields(output_dict, field_name, data_dict):\n",
    "    obj = data_dict.get(field_name)\n",
    "    for k, v in obj.items():\n",
    "        output_dict[k] = v.get(\"value\")\n",
    "        \n",
    "        \n",
    "def extract_values_fields(output_dict, field_name, data_dict):\n",
    "    obj = data_dict.get(field_name)\n",
    "    for k, v in obj.items():\n",
    "        values = v.get(\"values\")\n",
    "        for elem in values:\n",
    "            if \"::\" in elem:\n",
    "                key, value = elem.split(\"::\", 1)\n",
    "                output_dict[key] = value\n",
    "            else:\n",
    "                output_dict[k] = elem\n",
    "                \n",
    "    \n",
    "        \n",
    "def extract_property_raw(output_dict: Dict[str, Any], field_name: str, data_dict: Mapping[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Хотим:\n",
    "      - property_raw: расплющить весь объект data_dict[\"property_raw\"]\n",
    "      - buildingProperties: расплющить либо data_dict[\"buildingProperties\"],\n",
    "        либо data_dict[\"property_raw\"][\"buildingProperties\"] (в твоём примере оно там)\n",
    "\n",
    "    Ключи делаем плоскими, например:\n",
    "      property_raw__condition = \"TO_RENOVATION\"\n",
    "      property_raw__area__value = 56.25\n",
    "      property_raw__buildingProperties__year = 1970\n",
    "      buildingProperties__year = 1970\n",
    "      buildingProperties__security__ = \"ANTI_BURGLARY_DOOR\"\n",
    "    \"\"\"\n",
    "\n",
    "    def flatten(obj: Any, prefix: str) -> None:\n",
    "        # словарь\n",
    "        if isinstance(obj, Mapping):\n",
    "            for kk, vv in obj.items():\n",
    "                if kk == \"__typename\":\n",
    "                    # почти всегда мусор для ML\n",
    "                    continue\n",
    "                flatten(vv, prefix + str(kk) + \"__\")\n",
    "            return\n",
    "\n",
    "        # список/кортеж\n",
    "        if isinstance(obj, list) or isinstance(obj, tuple):\n",
    "            output_dict[prefix] = obj\n",
    "            return\n",
    "\n",
    "        # скаляр\n",
    "        if prefix.endswith(\"__\"):\n",
    "            prefix_key = prefix[:-2]\n",
    "        else:\n",
    "            prefix_key = prefix\n",
    "        output_dict[prefix_key] = obj\n",
    "\n",
    "    if field_name == \"property_raw\":\n",
    "        obj = data_dict.get(\"property_raw\")\n",
    "        if obj is None:\n",
    "            output_dict[\"property_raw\"] = None\n",
    "            return\n",
    "        flatten(obj, \"property_raw__\")\n",
    "        return\n",
    "\n",
    "    if field_name == \"buildingProperties\":\n",
    "        obj = data_dict.get(\"buildingProperties\")\n",
    "        if obj is None:\n",
    "            pr = data_dict.get(\"property_raw\")\n",
    "            if isinstance(pr, Mapping):\n",
    "                obj = pr.get(\"buildingProperties\")\n",
    "\n",
    "        if obj is None:\n",
    "            output_dict[\"buildingProperties\"] = None\n",
    "            return\n",
    "\n",
    "        flatten(obj, \"buildingProperties__\")\n",
    "        return\n",
    "\n",
    "    # fallback (если позже добавишь что-то ещё в этот extractor)\n",
    "    obj = data_dict.get(field_name)\n",
    "    if obj is None:\n",
    "        output_dict[field_name] = None\n",
    "        return\n",
    "    flatten(obj, field_name + \"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dbc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_processing = [\n",
    "    (\"char\", extract_char_fields),\n",
    "    (\"top_info\", extract_values_fields),\n",
    "    (\"additional_info\", extract_values_fields),\n",
    "    (\"ad_id\", simple_get_field),\n",
    "    (\"url\", simple_get_field), \n",
    "    (\"status\", simple_get_field),\n",
    "    (\"created_at\", simple_get_field),\n",
    "    (\"modified_at\", simple_get_field),\n",
    "    (\"pushed_up_at\", simple_get_field),\n",
    "    (\"title\", simple_get_field),\n",
    "    (\"seo_title\", simple_get_field),\n",
    "    (\"seo_description\", simple_get_field),\n",
    "    (\"description_text\", simple_get_field),\n",
    "    (\"market\", simple_get_field),\n",
    "    (\"advertiser_type\", simple_get_field),\n",
    "    (\"advert_type\", simple_get_field),\n",
    "    (\"exclusive_offer\", simple_get_field),\n",
    "    (\"latitude\", simple_get_field),\n",
    "    (\"longitude\", simple_get_field),\n",
    "    (\"street\", simple_get_field),\n",
    "    (\"street_number\", simple_get_field),\n",
    "    (\"district\", simple_get_field),\n",
    "    (\"city\", simple_get_field),\n",
    "    (\"county\", simple_get_field),\n",
    "    (\"province\", simple_get_field),\n",
    "    (\"postal_code\", simple_get_field),\n",
    "    (\"location_text\", simple_get_field),\n",
    "    (\"features\", simple_get_field),\n",
    "    (\"agency_name\", simple_get_field),\n",
    "    (\"price_pln\", simple_get_field),\n",
    "    (\"area_m2\", simple_get_field),\n",
    "    (\"price_per_m2_pln\", simple_get_field),\n",
    "    (\"rooms\", simple_get_field),\n",
    "    (\"building_floors\", simple_get_field),\n",
    "    (\"year_built\", simple_get_field),\n",
    "    (\"rent_pln\", simple_get_field),\n",
    "    (\"floor\", simple_get_field),\n",
    "    (\"lift\", simple_get_field),\n",
    "    (\"property_raw\", extract_property_raw),\n",
    "    (\"buildingProperties\", extract_property_raw),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3da05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_listing(data_dict: Mapping[str, Any], fields_processing: list[tuple[str, Any]]) -> Dict[str, Any]:\n",
    "    out: Dict[str, Any] = {}\n",
    "    for field_name, fn in fields_processing:\n",
    "        fn(out, field_name, data_dict)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads_df = pd.DataFrame(df['payload'].apply(lambda x: process_listing(x, fields_processing)).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f64fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(payloads_df.isna().sum() / len(payloads_df)).sort_values(ascending=False).iloc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Nan columns\n",
    "payloads_df = payloads_df.drop(columns=[\"property_raw__rent\",                           \n",
    "                         \"property_raw__properties__type\",                     \n",
    "                         \"postal_code\",                                        \n",
    "                         \"property_raw__id\",                                   \n",
    "                         \"flat_projection\",                                    \n",
    "                         \"street_number\",                                      \n",
    "                         \"flat_number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7416c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3dbeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads_df = payloads_df[~payloads_df[\"price_per_m2_pln\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac56d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ---------- parsing helpers ----------\n",
    "\n",
    "def parse_pln(x):\n",
    "    \"\"\"'1 200 zł' -> 1200.0 ; '600 zl' -> 600.0 ; NaN -> NaN\"\"\"\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x)\n",
    "    s = str(x).lower().strip()\n",
    "    if s in {\"\", \"nan\", \"none\", \"null\"}:\n",
    "        return np.nan\n",
    "    s = s.replace(\"zł\", \"\").replace(\"zl\", \"\").strip()\n",
    "    s = s.replace(\" \", \"\")\n",
    "    s = re.sub(r\"[^0-9.]\", \"\", s)\n",
    "    return float(s) if s else np.nan\n",
    "\n",
    "\n",
    "def parse_floor_no(x):\n",
    "    \"\"\"'floor_4'/'FLOOR_4' -> (4,0), 'ground_floor'/'GROUND_FLOOR' -> (0,1)\"\"\"\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return (np.nan, 0)\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"ground_floor\", \"parter\", \"0\", \"floor_0\"}:\n",
    "        return (0, 1)\n",
    "    m = re.search(r\"(\\d+)\", s)\n",
    "    if m:\n",
    "        return (int(m.group(1)), 0)\n",
    "    return (np.nan, 0)\n",
    "\n",
    "\n",
    "def _looks_multilabel_value(v) -> bool:\n",
    "    if isinstance(v, (list, tuple, set)):\n",
    "        return True\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            return True\n",
    "        if \"|\" in s:\n",
    "            return True\n",
    "        # осторожно с ',' — в адресах/seo оно встречается часто\n",
    "        # для multi-label обычно видно много запятых + короткие токены\n",
    "        if \",\" in s and len(s) < 120:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def parse_to_list(v):\n",
    "    \"\"\"Robust: list -> list[str], \"['a','b']\" -> ['a','b'], \"a|b\" -> ['a','b'], \"\" -> []\"\"\"\n",
    "    if v is None or (isinstance(v, float) and np.isnan(v)):\n",
    "        return []\n",
    "    if isinstance(v, (list, tuple, set)):\n",
    "        return [str(x).strip() for x in v if str(x).strip()]\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip()\n",
    "        if s == \"\" or s.lower() in {\"nan\", \"none\", \"null\"}:\n",
    "            return []\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                obj = ast.literal_eval(s)\n",
    "                if isinstance(obj, (list, tuple, set)):\n",
    "                    return [str(x).strip() for x in obj if str(x).strip()]\n",
    "                return [str(obj).strip()] if str(obj).strip() else []\n",
    "            except Exception:\n",
    "                # fallback: strip brackets and split by comma\n",
    "                inner = s[1:-1].strip()\n",
    "                if not inner:\n",
    "                    return []\n",
    "                parts = [p.strip().strip(\"'\").strip('\"') for p in inner.split(\",\")]\n",
    "                return [p for p in parts if p]\n",
    "        if \"|\" in s:\n",
    "            return [p.strip() for p in s.split(\"|\") if p.strip()]\n",
    "        # comma-split only if it's not a \"long text\"\n",
    "        if \",\" in s and len(s) < 120:\n",
    "            return [p.strip() for p in s.split(\",\") if p.strip()]\n",
    "        return [s]\n",
    "    return [str(v).strip()] if str(v).strip() else []\n",
    "\n",
    "\n",
    "def detect_multilabel_columns(df: pd.DataFrame, candidate_cols: list[str], sample_n: int = 50) -> list[str]:\n",
    "    multi = []\n",
    "    for col in candidate_cols:\n",
    "        s = df[col].dropna()\n",
    "        if s.empty:\n",
    "            continue\n",
    "        sample = s.sample(min(sample_n, len(s)), random_state=42).tolist()\n",
    "        share = np.mean([_looks_multilabel_value(v) for v in sample])\n",
    "        if share >= 0.25:\n",
    "            multi.append(col)\n",
    "    return multi\n",
    "\n",
    "\n",
    "# ---------- MultiLabel transformer ----------\n",
    "\n",
    "class MultiLabelBinarizerFrame(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns: list[str]):\n",
    "        self.columns = columns\n",
    "        self.mlbs: dict[str, MultiLabelBinarizer] = {}\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        for col in self.columns:\n",
    "            lists = X[col].map(parse_to_list)\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(lists)\n",
    "            self.mlbs[col] = mlb\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        mats = []\n",
    "        for col in self.columns:\n",
    "            lists = X[col].map(parse_to_list)\n",
    "            mats.append(self.mlbs[col].transform(lists))\n",
    "        if not mats:\n",
    "            return np.empty((len(X), 0))\n",
    "        return np.concatenate(mats, axis=1)\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        names = []\n",
    "        for col, mlb in self.mlbs.items():\n",
    "            names.extend([f\"{col}__{c}\" for c in mlb.classes_])\n",
    "        return np.array(names, dtype=object)\n",
    "\n",
    "\n",
    "# ---------- main feature prep ----------\n",
    "\n",
    "def prepare_Xy_and_preprocessor(df: pd.DataFrame, target=\"price_per_m2_pln\"):\n",
    "    df = df.copy()\n",
    "\n",
    "    # target\n",
    "    y = df[target].astype(float)\n",
    "\n",
    "    # drop obvious leakage + text\n",
    "    drop_cols = [\n",
    "        target,\n",
    "        \"price\", \"price_pln\", \"price_per_m\",\n",
    "        \"url\", \"ad_id\",\n",
    "        \"title\", \"seo_title\", \"seo_description\", \"description_text\",\n",
    "        \"status\", \"location_text\",\n",
    "        \"created_at\", \"modified_at\", \"pushed_up_at\",\n",
    "        \"Unnamed: 15\", \"\",  # empty col name\n",
    "        # noisy split columns\n",
    "        \"extras_types-85\", \"construction_status-67\", \"building_material-69\",\n",
    "    ]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    # keep one of duplicates (prefer *_m2, rooms, year_built, building_floors)\n",
    "    # if these exist, drop the alternatives\n",
    "    dup_drop = []\n",
    "    if \"area_m2\" in df.columns:\n",
    "        dup_drop += [c for c in [\"m\", \"area\", \"property_raw__area__value\"] if c in df.columns]\n",
    "    if \"rooms\" in df.columns:\n",
    "        dup_drop += [c for c in [\"rooms_num\", \"property_raw__properties__numberOfRooms\"] if c in df.columns]\n",
    "    if \"year_built\" in df.columns:\n",
    "        dup_drop += [c for c in [\"build_year\", \"buildingProperties__year\", \"property_raw__buildingProperties__year\"] if c in df.columns]\n",
    "    if \"building_floors\" in df.columns:\n",
    "        dup_drop += [c for c in [\"building_floors_num\", \"buildingProperties__numberOfFloors\", \"property_raw__buildingProperties__numberOfFloors\"] if c in df.columns]\n",
    "    df = df.drop(columns=list(set(dup_drop)), errors=\"ignore\")\n",
    "\n",
    "    # parse rent\n",
    "    if \"rent\" in df.columns:\n",
    "        df[\"rent_pln_num\"] = df[\"rent\"].map(parse_pln)\n",
    "        df = df.drop(columns=[\"rent\"], errors=\"ignore\")\n",
    "\n",
    "    # parse floor_no\n",
    "    if \"floor_no\" in df.columns:\n",
    "        tmp = df[\"floor_no\"].map(parse_floor_no)\n",
    "        df[\"floor_no_num\"] = [t[0] for t in tmp]\n",
    "        df[\"is_ground_floor\"] = [t[1] for t in tmp]\n",
    "        df = df.drop(columns=[\"floor_no\"], errors=\"ignore\")\n",
    "\n",
    "    # parse free_from date\n",
    "    if \"free_from\" in df.columns:\n",
    "        dt = pd.to_datetime(df[\"free_from\"], errors=\"coerce\")\n",
    "        df[\"free_from_year\"] = dt.dt.year\n",
    "        df[\"free_from_month\"] = dt.dt.month\n",
    "        df = df.drop(columns=[\"free_from\"], errors=\"ignore\")\n",
    "\n",
    "    # building age\n",
    "    if \"year_built\" in df.columns:\n",
    "        df[\"building_age\"] = (2026 - pd.to_numeric(df[\"year_built\"], errors=\"coerce\")).clip(lower=0)\n",
    "\n",
    "    # split types\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    bool_cols = df.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "    obj_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "    # detect multilabel among object columns (НО: исключаем geo/address-like long text)\n",
    "    # например street может содержать запятые, но это не multi-label\n",
    "    blocklist = {\"street\", \"county\"}  # street лучше либо убрать, либо оставить как single-cat без split\n",
    "    candidate_obj = [c for c in obj_cols if c not in blocklist]\n",
    "\n",
    "    multilabel_cols = detect_multilabel_columns(df, candidate_obj)\n",
    "    cat_cols = [c for c in obj_cols if c not in multilabel_cols]\n",
    "\n",
    "    # fill numeric NaN\n",
    "    df[num_cols] = df[num_cols].fillna(df[num_cols].median(numeric_only=True))\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "            (\"bool\", \"passthrough\", bool_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=2, sparse_output=True), cat_cols),\n",
    "            (\"mlb\", MultiLabelBinarizerFrame(multilabel_cols), multilabel_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3,\n",
    "    )\n",
    "\n",
    "    X = df\n",
    "    info = {\"num\": num_cols, \"bool\": bool_cols, \"cat\": cat_cols, \"multilabel\": multilabel_cols}\n",
    "    return X, y, preprocessor, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa56e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, preprocessor, info = prepare_Xy_and_preprocessor(payloads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bd2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(new_X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"lgbm\", model),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Val score R2:\", pipe.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4a7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
